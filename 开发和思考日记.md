##7月9日
拿links数据尝试运行一个逻辑回归的样例，遇到特征向量的问题。
如何基于已有的DF定义为每一条记录定义一个vector？
##7月11日
分析了4个表里的数据，发现links并不适合来做LR。另外也在寻找数据挖掘方面的开发指南。
#数据和字段的含义
links是一部电影在三家网站上的ID，其中有3个字段：
movieId,电影在movielens网站上的ID。
imdbId,电影在IMDB网站上的ID。
tmdbId,电影在TMDB网站上的ID。

movies是电影的情况
movieId,电影在movielens网站上的ID。
title,电影名
genres,电影的分类

ratings是不同的用户对不同的电影所做的评分，多对多的关系。
userId,参与评分的用户的ID
movieId,电影的ID
rating,某个用户对某部电影的评分
timestamp,时间戳

tags是用户对电影的评价情况
userId,参与评分的用户的ID
movieId,电影的ID
tag,标签，或者说是该用户对电影的简单评语
timestamp,时间戳

#问题
如何基于已有数据构建向量，如何给电影打标签，给用户打标签？

##7月12日
青云

服务器一 ：121.201.8.24 用户:root 密码: Spark123 

开发环境安装在/opt


#######2016-07-13(yuwangtian)#################

搭建2台青云服务器cpu:2+内存*2G   *2
master+slave1

(spark)   http://121.201.8.24:8080/

(hadoop)  http://121.201.8.24:50070/


服务器二：121.201.14.139  


-/opt/*

|-- data
|-- hadoop-2.6.4
|-- install
|-- kafka-2.11
`-- spark-1.6.1.

#############################################

##7月13日_罗辉
感谢余陈和清扬搭建的集群。目前有这些基本就可以开发了。
To 清扬
你这边可以开始着手sparkstreaming+mllib的开发。
这个部分需要先构建
1.kafka输入流，清扬可以自己定拿什么数据往kafka producer里塞。
我之前的一个想法是取一部分经过清洗后的rating的数据，按最后一个字段timestamp做降序排列，然后取前30%的。
这样取出来的就是在时间上靠后的30的数据，这部分做为流数据，把他们按照一定的速度打入sparkstreaming.
2.一个sparkstreaming+kafka的应用，可以参考http://spark.apache.org/docs/latest/streaming-kafka-integration.html。
在这个里面有2种接收Kafka的流数据的方式，推荐第二种，Direct Approach.
3.流式数据的数据挖掘，参考http://spark.apache.org/docs/latest/streaming-programming-guide.html#mllib-operations
另外我记得databrick也曾经有过相关的博客或者是视频，我以前看到过，不记得是RX讲的还是TD讲的了。清扬可以找找看。

所以在这里基本上会用到SparkSQL,SparkStreaming+SparkSQL+MLlib.

To 余陈
你这边搭建集群的任务暂时先告一段落，然后后面就是随着咱们的应用的开发情况你可以考虑配置一些参数。比较常用的有内存大小的分配，并行度，classpath，storage等等。
大伙跑的时候想调的话可以加，不过最好是记录下或者说一声。
然后接下来你可以自己选择是进入推荐模块的开发还是流计算模块的开发。这个基本上都需要搞搞。

  
  

To 刘能
你这边开始怎么样，万事开头难。你可以先看下怎么用github，把咱们项目拉下来，然后开始弄，我好像还没有添加你的GITHUB账号。
你把账号发给我，没有的话申请一个，正好是一次学习使用GITHUB的机会。

另外于宏学这边工作可能比较忙，我明天打个电话问问他。WEB部分的工作也是很重要的一块。
再次我这边还是在特征向量的提取上做一些尝试，以及看一些项目整体上的情况。
关于把项目转成私有项目，我可能还得看看怎么弄，还真不知道怎么转成private的。


余陈 RE:罗辉  2016-07-14
#####################################################################################
spark地址默认参数设置
配置文件地址 src\main\resources\util.properties
jar包classpass，src\main\resources\META-INF\MANIFEST.MF
jar包在服务器的地址：/opt/data/jar/BraveFirst.jar
centos7 master服务器：121.201.8.24
用户：root
密码：Spark123

执行命令（运行）：
cd /opt/spark-1.6.1/bin
./spark-submit  /opt/data/jar/BraveFirst.jar
运行demo的结果：
+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+
访问页面地址：http://121.201.8.24:8080
#####################################################################################

##7月14日罗辉
今天讨论了一下推荐的思路，目前暂定的就是用矩阵分解。
#
不过第一步首先是给用户和电影打标签。然后刘能这边可以稍微整理下一个思路，有了GITHUB的权限可以把文档放上来了。
#
项目私有化我也看了，每天7美刀，我感觉可以稍微再晚点。信用卡我这边有。这个倒不是事。

##7月17日罗辉
这两天把集群调了一下，数据都已经放到集群里了，本地路径和HDFS，以及spark-sql里都有。集群的使用手册参考青云Spark集群使用说明.md 
#
项目的JAR包我放到集群$SPARK_HOME目录下了。
#
然后大伙在开发的时候遇到什么问题就在群里说，需要谁谁配合解决的直接@.都是自家队友，需要配合的速度提，相互支援是必须的。
To yuchen
util.property好像有点问题，帮忙看一下吧，我单独发截图给你了。

##7月17日清扬
kafka+sparkstreaming数据流:
#
#
###开启zk
#
zookeeper-server-start.sh /usr/lib/kafka/config/zookeeper.properties &
#
或
#
在/opt/install/zookeeper-3.4.6/bin 运行sh zkServer.sh start
#
#
###开一个或多个kafka broker
#
kafka-server-start.sh /usr/lib/kafka/config/server.properties &
#
kafka-server-start.sh /usr/lib/kafka/config/server1.properties &
#
#
###创建topic
#
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 2 --topic sparkmovie
#
#
###查看topic
#
kafka-topics.sh --list --zookeeper localhost:2181
#
#
###启动producer,目前可以直接从local推入kafka
#
kafka-console-produce.sh --broker-list localhost:9092 --topic sparkmovie < movies.txt
#
#
###启动consumer
#
(用于测试)kafka-console-consumer.sh --zookeeper localhost:2181 --topic sparkmovie --from-beginning
#
###或开启sparkStreaming消费
#
spark-submit --jars '/usr/lib/spark/lib/kafka-clients-0.10.0.0.jar,/usr/lib/spark/lib/spark-streaming-kafka_2.10-1.6.1.jar,/usr/lib/spark/lib/kafka_2.10-0.10.0.0.jar,/usr/lib/spark/lib/zkclient-0.8.jar,/usr/lib/spark/lib/metrics-core-2.2.0.jar' /opt/data/BraveFirst.jar 1000 60 5 sparkmovie 'zookeeper.connect=192.168.100.2:2181/mdata;group.id=spark-streaming-movieStream1;zookeeper.connection.timeout.ms=10000'
#
#
kafka-console-consumer.sh消费者能够成功收到数据,但是sparkStreaming消费出现以下错误,尝试了kafka自带zk,和另装的zk都是以下错误,望大家帮忙研究下
#
`16/07/17 18:04:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - org.I0Itec.zkclient.exception.ZkNoNodeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.I0Itec.zkclient.exception.ZkException.create(ZkException.java:47)
	at kafka.utils.ZKCheckedEphemeral.create(ZkUtils.scala:1112)
`


余陈 2016-07-18
#####################################################################################
一、配置spark history server
./sbin/start-history-server.sh
./sbin/stop-history-server.sh

http://121.201.8.24:18080/

也可以从http://121.201.8.24:8080/  Application的name中点击进入

Application ID	Name	Cores	Memory per Node	Submitted Time	User	State	Duration
app-20160718190406-0003	【KafkaStreaming】	8	1024.0 MB	2016/07/18 19:04:06	root	FINISHED	5 s



二、修改run.sh
$SPARK_HOME/bin/spark-submit BraveFirst.jar 1000 60 5 sparkmovie 'zookeeper.connect=192.168.100.2:2181/mdata;group.id=spark-streaming-movieStream1;zookeeper.connection.timeout.ms=10000'

目前BraveFirst.jar的classpath 还有点问题，跟我打包jar，MANIFEST.MF没有弄好。
不过目前，可以运行，能成功调用kafka，会有class not found的异常。
明天我继续解决
#####################################################################################

2016-07-19罗辉
今天清扬提了一个很好的建议，就是要有一定的项目管理，要再次明确任务和时间点。
#
我更新了咱们的任务，我给的时间是22号，到这周五。
#
我和余陈来开发，清扬做清洗，雄健和刘能定算法和模型
<<<<<<< HEAD
说实话，我没搞过推荐系统，也不知道难度怎么样，但是咱必须在前期得在时间上紧一点，这样才能尽可能的保证咱能在截止日期前提交出作品来。
做这个项目，参加这次比赛，实际就是一个挑战自我的过程。
=======
说实话，我没搞过推荐系统，也不知道难度怎么样，但是咱必须在前期得在时间上紧一点，这样才能尽可能的保证咱能在截止日期前提交出作品来。做这个项目，参加这次比赛，实际就是一个挑战自我的过程。


余陈 2016-07-20
#####################################################################################
今天补充一下RDD的一些基础知识，为以后开发做准备
转化              返回RDD
行动（Action）    返回其他类型

并阅读《kafka系列文档.pdf》85页
我对scala也不熟悉，今天购买了《快学Scala》402页，这本基础书籍估计过几天到济南


对于jar的class采用外部lib的方式对于jar太多，确实有问题
最后换了一种方式，打包将jar文件的class放在jar中，运行ok
不过有一个问题就是jar太大，从之前的90k变成180m，有点不方便

暂时没有很好的解决办法，不过这个暂时先这样，不是很紧要

另外：

我有一个技术上的小疑问
方式一：sparksql可以直接读取mysql，
方式二：spark通过hive，再通过hive去读取mysql
这两种方式哪个更好一点呢？
#####################################################################################
20160721罗辉
To yuchen
方式一：sparksql可以直接读取mysql更好.
###
To All
其实现在咱们可以不用看SparkSQL的部分，因为这个部分我已经做了。咱们现在需要尽快一起写出一个推荐出来。我再这里贴几个Spark官方给出的推荐的例子程序的链接，有ALS的，矩阵分解的，大家都可以看一下。
https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala
https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala
https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala
https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala
https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala
https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/mllib/recommendation
##
我没有全部看完这些例子，大家可以挑一个开始动手改这些例子。应该也有对应的Java的版本的，咱不一定非得要用scala来实现，Java好搞可以就用Java先搞起来,python的也行，咱不限制语言。
推荐大家动手改写这些例子，按照我的经验，动手写这些代码是最快的理解Spark，理解RDD，理解dataframe,理解vector,理解metrics的最快的方式。
在IDE里边写的时候边看到这些对象的类型，你就能很快理解RDD是怎么变成dataframe,或者是其他类型的东东的了。

##
20160721罗辉
咱们本周的任务是完成一个推荐系统的原形。根据这个目标，有关目前任务进度的部分，大家伙都自己给自己定一个目标和时间点，输出什么代码或者文档之类。
明确一下自己当前在做的任务，截止的时间点，完成的情况，遇到的问题。
我更新了一个EXCEL在咱项目的DOCS里面，大家根据自己现在在做的事，填一个力所能及的，比较具体的任务目标，以及时间点。
我想咱们每3天做一个小周期，来看下当前任务完成情况，以及哪边遇到了问题，是否有卡壳点，是否需要支援等等。
尽量保证咱们这个项目能以团队的力量来完成他，而不是每个人都是孤独在扛着自己的那一块，相互之间有个搭手。
##
另外，我这边已经完成了推荐系统原形的开发。已经能成功推荐出东西来了。
##
the recommandation movies for specified user NO.12345 is :    
##                  
[Dark Eyes (Oci ciornie) (1987)]
##
[Rosario Tijeras (2005)]
##
[Film Geek (2005)]
##
[Queen: Days of Our Lives (2011)]
##
[Seoul Searching (2015)]
##
the recommandation movies for a random user NO.64535 is :
##
[Bj枚rk: Volumen (1999)]
##
[Seoul Searching (2015)]
##
Mean Squared Error = 0.5141435479649239 
##
剩下就是调模型，然后让余陈帮忙搭个简单的WEB，展示咱推荐的结果。
##
另外就是实时推荐，因为模型已经训练好了，虽然这模型的MSE很渣，位置在HDFS上的/USER/ROOT/MODEL里面
##
大家伙加油！




余陈 2016-07-22
#####################################################################################
已搭建了一个简单的web
http://121.201.8.24:8090
启动命令：$t/bin/startup.sh


后续再从其中选择一个合适的页面
#####################################################################################

##7月22.23日清扬
##
这两天的清洗工作:
##
1. 生成唯一用户列表
##
2. 修改代码,ETL解决第二列带逗号问题
##
3. 过滤掉(no genres listed)的movie；同时过滤出这样的movie，共579行，需要人工标签
##
4. movies用excel按照title字典顺序排序未发现重复
##
5. tags数据排查,tag部分是否使用(部分是电影类型)
##
6. 查重复id:用excel条件格式功能未发现重复id

######################################################################################
##7月24日刘能
原先的一个Model类现在变成2个类：AlsModelTraning.scala 此类专门用来训练模型，
附带一些指标计算方法用来测试模型的准确度，最终将训练好的模型保存到本地或者HDFS；
Recommendation.scala 这个类从本地或者HDFS加载训练好的模型直接做推荐，今晚跑了下直接挂了，明天有时间再优化一下！

余陈 2016-07-22
#####################################################################################
搭建一个简单推荐页面，输入用户ID弹出电影列表

通过links.txt思考：讲两个网站的id用起来，可以获取链接

目前获取电影的图片，好像有点问题，还需要用爬虫

剩下的工作：
1.页面：将弹出信息，渲染到页面

2.数据：将推荐结果，放在mysql数据库中表user_moive_recommandation

主键 userid	moiveid	name	电影图片链接	电影链接
1	    2	French Twist	www.baidu.com	www.baidu.com
1	    3	Unforgettable	www.baidu.com	www.baidu.com
2	    6	Anne Frank Remembered	www.baidu.com	www.baidu.com

初始化了一个demo数据，用于web页面的测试。但是需要将真正推荐的数据放进来
http://121.201.8.24:8090/

$t/bin/startup.sh      （开机以后启动tomcat，才能访问）

####################################################################################
20160728_罗辉
今天总算把JAR包不能运行的问题解决了，现在在调试kafka的producer的问题。
之前用scala.source来读取本地路径上的文件，后来发现不管是绝对路径还是相对路径都读不到，挺奇怪的。
于是只好通过sparkContext来读这个文件，然后随便给点内容转成字符串在里面去输出，结果又遇到了akka版本的问题。这个也很奇怪，通常都不需要去设置akka的版本的说。在props对象里强行设定了这个参数也无效。
查阅了spark和kafka的参数列表，里面也没有akka.version这个参数。。。
另外，大家伙也争取加加油，8月10日是周三，咱们争取10号之前能提交一个比较像样点的项目。
####
开发和思考_zhao0731
##
主题：实现基于物品的推荐流程
###
过程：1.将movies表的genres与movieId转化成matrix表，转换代码采用python语言
     2.将matrix表转成matrix2表，转换代码采用python语言
	 3.计算matrix2表中的行距离（目前采用欧几里得距离，可根据需要随时更改），每一个电影Id挑选结果最大的10个其他的Id，
	   将筛选结果存于result表中，采用R语言
###
问题：1. python语言的常用库对矩阵运算的支持度不高，故计算向量距离时采用R，R的dist函数可以很方便的计算行距离，计算时间3-5
     分钟，然而结果为下三角矩阵，不方便后续的排序，当转成方阵时，系统提示内存溢出，本地环境内存为8G。后自己编写计算过程，
	 计算时间超过8小时（计算次数大概在10亿），仍未出结果，原因是执行过程是顺序的。此两种方法为两个极端，一个过度消耗内存，
	 一个耗时过长，可采取多线程的方式解决，开500个进程应该能明显改观，暂未研究R对多线程支持程度。
	 2. 暂不清楚如何引入训练集与测试集，无法验证何种距离函数效果更好
	 3. 推荐结果是否可能结合
	
#######################################################################################
20160801_罗辉
剩下到8月10日还有10天的时间，10号是周三。我们还有9天的时间来完成并提交我们的第一版的作品。我整理了一个文档《参赛作品的要求》，列出了比赛规定的参赛作品需要包含的内容。 
##
另外就是雄健这边遇到模型转换上的一个问题，可能需要用SparkR来解决，有可能需要把他的R的代码移植到SparkR上，所以可能需要看谁能配合一下。

To yuchen
由于最后提交的作品是需要有文档，视频和结果截图的。所以你那边可能需要事先准备一个运行结果的截图，我到时候看把它放到视频里还是放到MarkDown文件里。

8月1日~8月10日的日程表

8月1日~8月3日               实时推荐模块的开发									罗辉，清扬

8月1日~8月3日		基于物品的推荐模块的开发								雄健，刘能

8月1日~8月3日		电影图片爬虫的开发，推荐结果写入MYSQL						余陈

8月4日~8月5日		系统整合											罗辉，清扬，余陈

8月5日			各个部分的开发思路，流程，展示，分析之类的文档书写				所有人

8月5日			提交推荐系统的页面截图									余陈

8月6日			完成参赛作品说明文件MD格式文件的书写，转成PDF				罗辉

8月7日			完成作品视频的录制，上传优酷以及youtube					罗辉

8月8日			预提交第一版或者测试版作品    								罗辉

8月9日~10日	 	提交第一版作品										罗辉


余陈 2016-08-01
#####################################################################################
1.完成电影图片和链接的爬取，刚爬了100多个，数据库连接池有点问题，还需要弄一下，剩余的电影还需要爬取数据
2.完成推荐页面和数据库交互

3.推荐结果还没有保存到mysql中，我需要研究一下，还不是很熟悉
4.已经将本地mysql的4张表同步到青云的mysql中（moive，moive_links，moive_url，user_moive_recommandation）

#####################################################################################