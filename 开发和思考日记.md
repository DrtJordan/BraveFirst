##7月9日
拿links数据尝试运行一个逻辑回归的样例，遇到特征向量的问题。
如何基于已有的DF定义为每一条记录定义一个vector？
##7月11日
分析了4个表里的数据，发现links并不适合来做LR。另外也在寻找数据挖掘方面的开发指南。
#数据和字段的含义
links是一部电影在三家网站上的ID，其中有3个字段：
movieId,电影在movielens网站上的ID。
imdbId,电影在IMDB网站上的ID。
tmdbId,电影在TMDB网站上的ID。

movies是电影的情况
movieId,电影在movielens网站上的ID。
title,电影名
genres,电影的分类

ratings是不同的用户对不同的电影所做的评分，多对多的关系。
userId,参与评分的用户的ID
movieId,电影的ID
rating,某个用户对某部电影的评分
timestamp,时间戳

tags是用户对电影的评价情况
userId,参与评分的用户的ID
movieId,电影的ID
tag,标签，或者说是该用户对电影的简单评语
timestamp,时间戳

#问题
如何基于已有数据构建向量，如何给电影打标签，给用户打标签？

##7月12日
青云

服务器一 ：121.201.8.24 用户:root 密码: Spark123 

开发环境安装在/opt


#######2016-07-13(yuwangtian)#################

搭建2台青云服务器cpu:2+内存*2G   *2
master+slave1

(spark)   http://121.201.8.24:8080/

(hadoop)  http://121.201.8.24:50070/


服务器二：121.201.14.139  


-/opt/*

|-- data
|-- hadoop-2.6.4
|-- install
|-- kafka-2.11
`-- spark-1.6.1.

#############################################

##7月13日_罗辉
感谢余陈和清扬搭建的集群。目前有这些基本就可以开发了。
To 清扬
你这边可以开始着手sparkstreaming+mllib的开发。
这个部分需要先构建
1.kafka输入流，清扬可以自己定拿什么数据往kafka producer里塞。
我之前的一个想法是取一部分经过清洗后的rating的数据，按最后一个字段timestamp做降序排列，然后取前30%的。
这样取出来的就是在时间上靠后的30的数据，这部分做为流数据，把他们按照一定的速度打入sparkstreaming.
2.一个sparkstreaming+kafka的应用，可以参考http://spark.apache.org/docs/latest/streaming-kafka-integration.html。
在这个里面有2种接收Kafka的流数据的方式，推荐第二种，Direct Approach.
3.流式数据的数据挖掘，参考http://spark.apache.org/docs/latest/streaming-programming-guide.html#mllib-operations
另外我记得databrick也曾经有过相关的博客或者是视频，我以前看到过，不记得是RX讲的还是TD讲的了。清扬可以找找看。

所以在这里基本上会用到SparkSQL,SparkStreaming+SparkSQL+MLlib.

To 余陈
你这边搭建集群的任务暂时先告一段落，然后后面就是随着咱们的应用的开发情况你可以考虑配置一些参数。比较常用的有内存大小的分配，并行度，classpath，storage等等。
大伙跑的时候想调的话可以加，不过最好是记录下或者说一声。
然后接下来你可以自己选择是进入推荐模块的开发还是流计算模块的开发。这个基本上都需要搞搞。

  
  

To 刘能
你这边开始怎么样，万事开头难。你可以先看下怎么用github，把咱们项目拉下来，然后开始弄，我好像还没有添加你的GITHUB账号。
你把账号发给我，没有的话申请一个，正好是一次学习使用GITHUB的机会。

另外于宏学这边工作可能比较忙，我明天打个电话问问他。WEB部分的工作也是很重要的一块。
再次我这边还是在特征向量的提取上做一些尝试，以及看一些项目整体上的情况。
关于把项目转成私有项目，我可能还得看看怎么弄，还真不知道怎么转成private的。


余陈 RE:罗辉  2016-07-14
#####################################################################################
spark地址默认参数设置
配置文件地址 src\main\resources\util.properties
jar包classpass，src\main\resources\META-INF\MANIFEST.MF
jar包在服务器的地址：/opt/data/jar/BraveFirst.jar
centos7 master服务器：121.201.8.24
用户：root
密码：Spark123

执行命令（运行）：
cd /opt/spark-1.6.1/bin
./spark-submit  /opt/data/jar/BraveFirst.jar
运行demo的结果：
+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+
访问页面地址：http://121.201.8.24:8080
#####################################################################################

##7月14日罗辉
今天讨论了一下推荐的思路，目前暂定的就是用矩阵分解。
#
不过第一步首先是给用户和电影打标签。然后刘能这边可以稍微整理下一个思路，有了GITHUB的权限可以把文档放上来了。
#
项目私有化我也看了，每天7美刀，我感觉可以稍微再晚点。信用卡我这边有。这个倒不是事。

##7月17日罗辉
这两天把集群调了一下，数据都已经放到集群里了，本地路径和HDFS，以及spark-sql里都有。集群的使用手册参考青云Spark集群使用说明.md 
#
项目的JAR包我放到集群$SPARK_HOME目录下了。
#
然后大伙在开发的时候遇到什么问题就在群里说，需要谁谁配合解决的直接@.都是自家队友，需要配合的速度提，相互支援是必须的。
To yuchen
util.property好像有点问题，帮忙看一下吧，我单独发截图给你了。

##7月17日清扬
kafka+sparkstreaming数据流:
#
#
###开启zk
#
zookeeper-server-start.sh /usr/lib/kafka/config/zookeeper.properties &
#
或
#
在/opt/install/zookeeper-3.4.6/bin 运行sh zkServer.sh start
#
#
###开一个或多个kafka broker
#
kafka-server-start.sh /usr/lib/kafka/config/server.properties &
#
kafka-server-start.sh /usr/lib/kafka/config/server1.properties &
#
#
###创建topic
#
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 2 --topic sparkmovie
#
#
###查看topic
#
kafka-topics.sh --list --zookeeper localhost:2181
#
#
###启动producer,目前可以直接从local推入kafka
#
kafka-console-produce.sh --broker-list localhost:9092 --topic sparkmovie < movies.txt
#
#
###启动consumer
#
(用于测试)kafka-console-consumer.sh --zookeeper localhost:2181 --topic sparkmovie --from-beginning
#
###或开启sparkStreaming消费
#
spark-submit --jars '/usr/lib/spark/lib/kafka-clients-0.10.0.0.jar,/usr/lib/spark/lib/spark-streaming-kafka_2.10-1.6.1.jar,/usr/lib/spark/lib/kafka_2.10-0.10.0.0.jar,/usr/lib/spark/lib/zkclient-0.8.jar,/usr/lib/spark/lib/metrics-core-2.2.0.jar' /opt/data/BraveFirst.jar 1000 60 5 sparkmovie 'zookeeper.connect=192.168.100.2:2181/mdata;group.id=spark-streaming-movieStream1;zookeeper.connection.timeout.ms=10000'
#
#
kafka-console-consumer.sh消费者能够成功收到数据,但是sparkStreaming消费出现以下错误,尝试了kafka自带zk,和另装的zk都是以下错误,望大家帮忙研究下
#
`16/07/17 18:04:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Error starting receiver 0 - org.I0Itec.zkclient.exception.ZkNoNodeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.I0Itec.zkclient.exception.ZkException.create(ZkException.java:47)
	at kafka.utils.ZKCheckedEphemeral.create(ZkUtils.scala:1112)
`